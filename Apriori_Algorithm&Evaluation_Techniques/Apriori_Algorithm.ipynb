{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Apriori Algorithm**\n",
    "\n",
    "### **Introduction and step by step example solved for Apriori Algorithm**\n",
    "\n",
    "- ### **Introduction**\n",
    "  - Apriori Algorithm is a famous frequent pattern mining method.\n",
    "  - It scans dataset repeatedly and generate items sets by bottom - top approach.\n",
    "  - The name is Apriori because it uses prior knowledge of frequent itemset properties.\n",
    "    - #### **Situations Where Apriori is Used**\n",
    "      - **Retail** Local sellers bundle items like onions and potatoes or offer discounts because customers who buy one often buy the other, boosting sales.\n",
    "      - **Supermarkets** Bundling items like bread, butter, and jam for customer convenience and increased sales.\n",
    "      - This algorithm has utility in the field of healthcare as it can help in detecting adverse drug reactions (ADR) by producing association rules to indiacte the combination of medications and patient characteristics that could lead to ADRs.\n",
    "        - #### **Components**\n",
    "          - The core components of the Apriori Algorithm include\n",
    "            - **Support** The frequency of an itemset appearing in the dataset.\n",
    "            - **Confidence** The probability that an item is purchased given that another item is purchased.\n",
    "            - **Lift** The ratio of the observed support to that expected if the items were independent.\n",
    "        - #### **Example Scenario**\n",
    "          - Let us suppose, wh have 2000 customer transactions in a supermarket.\n",
    "          - We have to find the Support, Confidence and Lift for two items, say bread and jam. It is because people frequently bundle these two items together.\n",
    "          - Out of the 2000 transactions, 200 contain jam whereas 300 contain bread. These 300 transactions include a 100 that includes breads as well as jam.\n",
    "          - Using this data, we shall find out the Support, Confidence and Lift.\n",
    "          - **Calculations**\n",
    "            - **Support (Jam)**\n",
    "              - We can calculate the Support as a quotient of the division of the number of transactions containing that item by the total number of transactions.\n",
    "              - For our example -\n",
    "                - Support(Jam) = (Transactions involving jam)/(Total transactions)\n",
    "                  - = 200/2000\n",
    "                  - = 10%\n",
    "            - **Confidence (Bread and Jam)**\n",
    "              - Confidence is the likelihood that customers bought both bread and jam.\n",
    "              - Dividing the numebr of transactions that include both bread and jam bu the total number of transactions will give the confidence figure.\n",
    "              - Confidence (Bread and Jam)\n",
    "                - = (Transaction involving both bread and jam)/(Total transaction involving jam)\n",
    "                - = 100/200 = 50%\n",
    "              - It implies that 50% of customers who brought jam brought bread as well.\n",
    "            - **Lift**\n",
    "              - Lift is the increase in the ratio of the sale of bread when you sell jam.\n",
    "              - The lift can be calculated using the confidence of bread and jam divided by the support of jam.\n",
    "              - For our example -\n",
    "              - Lift = (Confidence (Bread and Jam))/(Support(Jam))\n",
    "                - = 50/10 = 5\n",
    "                - It says that the likelihood of a customer buying both jama and bread together is 5 times more than the chance of purchasing jam alone. If the Lift value is less than 1, It entails that the customers are unlikely to buy both the items together.\n",
    "                - **Greater the value, better is the combination.**\n",
    "          - #### **How does Apriori Algorithm Work?**\n",
    "            - We shall explain this using a very simple example.\n",
    "            - Consider a supermarket scenario where the itemset is | = {Onion, Burger,Potato, Milk, Beer}.\n",
    "            - The database consists of six transactions where 1 represents the presence of the item and 0 the absence.\n",
    "              - ![Apriori_Algorithm](<./Images/Apriori_Algorithm (1).png>)\n",
    "          - #### **Assumptions**\n",
    "            - The Apriori Algorithm makes the following assumptions.\n",
    "              - All subsets of a frequent itemset should be frequent.\n",
    "              - All subsets of an infrequent itemset should be indrequent.\n",
    "              - Set a thereshold support level. In our case, we shall fix it at 50%.\n",
    "          - ### **Flowchart of Apriori Algorithm**\n",
    "            - The flowchart visualizes the step-by-step process of the Apriori algorithm, guiding through the process of generating frequent itemsets and association rules.\n",
    "            - ![Apriori_Algorithm](<./Images/Apriori_Algorithm (2).png>)\n",
    "          - #### **Taking the given example**\n",
    "            - ![Apriori_Algorithm](<./Images/Apriori_Algorithm (3).png>)\n",
    "            - ![Apriori_Algorithm](<./Images/Apriori_Algorithm (4).png>)\n",
    "            - ![Apriori_Algorithm](<./Images/Apriori_Algorithm (5).png>)\n",
    "          - ### **Subset Creation**\n",
    "            - The subset creation process involves generating combinations of items and filtering them based on the support threshold. The visuals illustrate how subsets are created and evaluated.\n",
    "            - ![Apriori_Algorithm](<./Images/Apriori_Algorithm (6).png>)\n",
    "            - ![Apriori_Algorithm](<./Images/Apriori_Algorithm (7).png>)\n",
    "\n",
    "---\n",
    "\n",
    "## **Project- Market Basket Analysis with Apriori Algorithm**\n",
    "\n",
    "- **Objective** Analyze transaction data using the Apriori algorithm to identify frequent itemsets and generate association rules.\n",
    "- **Description** For simplicity, we'll use a synthetic dataset created within the code rather than importing from an external file.\n",
    "\n",
    "### **Implementation**\n",
    "\n",
    "#### **Import necessary libraries**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Create a synthetic transaction dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'TransactionID': [1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4],\n",
    "    'Item': ['Milk', 'Bread', 'Milk', 'Bread', 'Butter', 'Milk', 'Bread', 'Butter', 'Milk', 'Bread', 'Butter']\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Preprocess the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    basket = (data.groupby(['TransactionID', 'Item'])['Item']\n",
    "              .count().unstack().reset_index().fillna(0)\n",
    "              .set_index('TransactionID'))\n",
    "    basket = basket.apply(lambda x: x > 0)\n",
    "    return basket\n",
    "\n",
    "basket_data = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Apply the Apriori algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_itemsets = apriori(basket_data, min_support=0.5, use_colnames=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Generate association rules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Display the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "   support               itemsets\n",
      "0     1.00                (Bread)\n",
      "1     0.75               (Butter)\n",
      "2     1.00                 (Milk)\n",
      "3     0.75        (Bread, Butter)\n",
      "4     1.00          (Milk, Bread)\n",
      "5     0.75         (Milk, Butter)\n",
      "6     0.75  (Milk, Bread, Butter)\n",
      "\n",
      "Association Rules:\n",
      "        antecedents      consequents  antecedent support  consequent support  \\\n",
      "0           (Bread)         (Butter)                1.00                0.75   \n",
      "1          (Butter)          (Bread)                0.75                1.00   \n",
      "2            (Milk)          (Bread)                1.00                1.00   \n",
      "3           (Bread)           (Milk)                1.00                1.00   \n",
      "4            (Milk)         (Butter)                1.00                0.75   \n",
      "5          (Butter)           (Milk)                0.75                1.00   \n",
      "6     (Milk, Bread)         (Butter)                1.00                0.75   \n",
      "7    (Milk, Butter)          (Bread)                0.75                1.00   \n",
      "8   (Bread, Butter)           (Milk)                0.75                1.00   \n",
      "9            (Milk)  (Bread, Butter)                1.00                0.75   \n",
      "10          (Bread)   (Milk, Butter)                1.00                0.75   \n",
      "11         (Butter)    (Milk, Bread)                0.75                1.00   \n",
      "\n",
      "    support  confidence  lift  leverage  conviction  zhangs_metric  \n",
      "0      0.75        0.75   1.0       0.0         1.0            0.0  \n",
      "1      0.75        1.00   1.0       0.0         inf            0.0  \n",
      "2      1.00        1.00   1.0       0.0         inf            0.0  \n",
      "3      1.00        1.00   1.0       0.0         inf            0.0  \n",
      "4      0.75        0.75   1.0       0.0         1.0            0.0  \n",
      "5      0.75        1.00   1.0       0.0         inf            0.0  \n",
      "6      0.75        0.75   1.0       0.0         1.0            0.0  \n",
      "7      0.75        1.00   1.0       0.0         inf            0.0  \n",
      "8      0.75        1.00   1.0       0.0         inf            0.0  \n",
      "9      0.75        0.75   1.0       0.0         1.0            0.0  \n",
      "10     0.75        0.75   1.0       0.0         1.0            0.0  \n",
      "11     0.75        1.00   1.0       0.0         inf            0.0  \n"
     ]
    }
   ],
   "source": [
    "print(\"Frequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "<div align=\"center\">\n",
    "    Created by Ankit Dimri  \n",
    "    © 2024\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
